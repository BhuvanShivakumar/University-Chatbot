{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de68ac2e-e34e-4184-9ff2-9683224ee94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.8182\n",
      "Precision: 0.8636\n",
      "Recall: 0.8182\n",
      "F1 Score: 0.8182\n",
      "------------------------------\n",
      "Fold 2\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.7273\n",
      "Precision: 0.6818\n",
      "Recall: 0.7273\n",
      "F1 Score: 0.6970\n",
      "------------------------------\n",
      "Fold 3\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 4\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9545\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 5\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "Fold 6\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 7\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 8\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.5000\n",
      "------------------------------\n",
      "Fold 9\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.8000\n",
      "Precision: 0.7500\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7667\n",
      "------------------------------\n",
      "Fold 10\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "\n",
      "Average Metrics Over All Folds:\n",
      "Average Training Time: 0.00 seconds\n",
      "Average Validation Accuracy: 0.8464\n",
      "Average Precision: 0.8659\n",
      "Average Recall: 0.8464\n",
      "Average F1 Score: 0.8467\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Dataset2.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Encode the tags\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(tags)\n",
    "\n",
    "# Vectorize the patterns using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(patterns)\n",
    "\n",
    "# Define the Naive Bayes model\n",
    "def create_model():\n",
    "    return MultinomialNB()\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "training_times = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model and measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    training_times.append(training_time)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f'Training Time: {training_time:.2f} seconds')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Precision: {val_precision:.4f}')\n",
    "    print(f'Recall: {val_recall:.4f}')\n",
    "    print(f'F1 Score: {val_f1:.4f}')\n",
    "    print(\"-\" * 30)\n",
    "    fold += 1\n",
    "\n",
    "# Print average metrics\n",
    "print(\"\\nAverage Metrics Over All Folds:\")\n",
    "print(f'Average Training Time: {np.mean(training_times):.2f} seconds')\n",
    "print(f'Average Validation Accuracy: {np.mean(val_accuracies):.4f}')\n",
    "print(f'Average Precision: {np.mean(val_precisions):.4f}')\n",
    "print(f'Average Recall: {np.mean(val_recalls):.4f}')\n",
    "print(f'Average F1 Score: {np.mean(val_f1s):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d3b4df-ecea-4846-97ac-68faa8c8b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is stance on ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The University's academic integrity policy (UPR AS14 Appendix III) [https://www.herts.ac.uk/__data/assets/pdf_file/0007/237625/AS14-Apx3-Academic-Misconduct-v17.0.pdf]sets out our stance on plagiarism including fake referencing which can often be the case with AI tools. Therefore, it is crucial thatyou do not use AI toolsto generate an assessment and submit it as your own work; to do so will constitute academic misconduct.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quuit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# Chatbot response function\n",
    "def get_response(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    sequence = vectorizer.transform([user_input])\n",
    "    prediction = model.predict(sequence)\n",
    "    tag = label_encoder.inverse_transform(prediction)[0]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802756ff-56ff-4beb-a041-1774485d7a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c33bd4a-568e-4ccb-ab1f-d8fe857a4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Encode the tags\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(tags)\n",
    "\n",
    "# Vectorize the patterns using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df47229-2a33-4bf5-b879-31f15358bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Grid Search: {'alpha': 2.0, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "# Define the Naive Bayes model\n",
    "def create_model(alpha=1.0, fit_prior=True):\n",
    "    return MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "\n",
    "# Hyperparameter tuning with Grid Search\n",
    "param_grid = {\n",
    "    'alpha': [0.0, 0.5, 1.0, 2.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters from Grid Search: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733e81e0-e7c4-47df-bd5e-08dff7781750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.6364\n",
      "Precision: 0.7273\n",
      "Recall: 0.6364\n",
      "F1 Score: 0.6667\n",
      "------------------------------\n",
      "Fold 2\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 3\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 4\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.8182\n",
      "Precision: 0.8182\n",
      "Recall: 0.8182\n",
      "F1 Score: 0.8182\n",
      "------------------------------\n",
      "Fold 5\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "Fold 6\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 7\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 8\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.6000\n",
      "Precision: 0.6000\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.6000\n",
      "------------------------------\n",
      "Fold 9\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "Fold 10\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "\n",
      "Average Metrics Over All Folds:\n",
      "Average Training Time: 0.00 seconds\n",
      "Average Validation Accuracy: 0.8673\n",
      "Average Precision: 0.8964\n",
      "Average Recall: 0.8673\n",
      "Average F1 Score: 0.8770\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the best model\n",
    "model = create_model(alpha=best_params['alpha'], fit_prior=best_params['fit_prior'])\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "training_times = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train the model and measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    training_times.append(training_time)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f'Training Time: {training_time:.2f} seconds')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Precision: {val_precision:.4f}')\n",
    "    print(f'Recall: {val_recall:.4f}')\n",
    "    print(f'F1 Score: {val_f1:.4f}')\n",
    "    print(\"-\" * 30)\n",
    "    fold += 1\n",
    "\n",
    "# Print average metrics\n",
    "print(\"\\nAverage Metrics Over All Folds:\")\n",
    "print(f'Average Training Time: {np.mean(training_times):.2f} seconds')\n",
    "print(f'Average Validation Accuracy: {np.mean(val_accuracies):.4f}')\n",
    "print(f'Average Precision: {np.mean(val_precisions):.4f}')\n",
    "print(f'Average Recall: {np.mean(val_recalls):.4f}')\n",
    "print(f'Average F1 Score: {np.mean(val_f1s):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "904e06ed-c0b4-49d3-b1c7-92a08a2d44d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hey! How can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# Chatbot response function\n",
    "def get_response(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    sequence = vectorizer.transform([user_input])\n",
    "    prediction = model.predict(sequence)\n",
    "    tag = label_encoder.inverse_transform(prediction)[0]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211967ac-99da-4e50-a5e7-3fa5d4b37abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3fa3b-fd9b-4344-a936-a06482b04ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83196f-1e91-4b81-b29a-f311a2c0cc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc03f4f-8307-4ee4-b2df-c2353d50e026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac118d9-4e95-49f9-921a-a6b473b0e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ec5e1a-387a-41aa-86be-59784dcd0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34038a7e-f3ab-4624-a112-07e42f1db5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc37bf4-69f6-4ebd-b836-7391ff99b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaf6492-0929-4ada-a6fc-6dbe51bfb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the tags\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b520ac1-92d3-4312-a8a4-c83667c0a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the patterns using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb2eff0-54c0-460e-8292-f59c6f618c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Naive Bayes model\n",
    "def create_model(alpha=1.0, fit_prior=True):\n",
    "    return MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a587ae-ce6c-4eb2-b425-6ed90ef2d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Grid Search: {'alpha': 2.0, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Grid Search\n",
    "param_grid = {\n",
    "    'alpha': [0.0, 0.5, 1.0, 2.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters from Grid Search: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "612fae5d-0195-4430-beb0-96accb034041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.6364\n",
      "Precision: 0.7273\n",
      "Recall: 0.6364\n",
      "F1 Score: 0.6667\n",
      "------------------------------\n",
      "Fold 2\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 3\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9091\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1 Score: 0.9091\n",
      "------------------------------\n",
      "Fold 4\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.8182\n",
      "Precision: 0.8182\n",
      "Recall: 0.8182\n",
      "F1 Score: 0.8182\n",
      "------------------------------\n",
      "Fold 5\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "Fold 6\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 7\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.9333\n",
      "------------------------------\n",
      "Fold 8\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 0.6000\n",
      "Precision: 0.6000\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.6000\n",
      "------------------------------\n",
      "Fold 9\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n",
      "Fold 10\n",
      "Training Time: 0.00 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the best model\n",
    "model = create_model(alpha=best_params['alpha'], fit_prior=best_params['fit_prior'])\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "training_times = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train the model and measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    training_times.append(training_time)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f'Training Time: {training_time:.2f} seconds')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Precision: {val_precision:.4f}')\n",
    "    print(f'Recall: {val_recall:.4f}')\n",
    "    print(f'F1 Score: {val_f1:.4f}')\n",
    "    print(\"-\" * 30)\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5185084c-9049-4a35-b049-315d59ed1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metrics Over All Folds:\n",
      "Average Training Time: 0.00 seconds\n",
      "Average Validation Accuracy: 0.8673\n",
      "Average Precision: 0.8964\n",
      "Average Recall: 0.8673\n",
      "Average F1 Score: 0.8770\n"
     ]
    }
   ],
   "source": [
    "# Print average metrics\n",
    "print(\"\\nAverage Metrics Over All Folds:\")\n",
    "print(f'Average Training Time: {np.mean(training_times):.2f} seconds')\n",
    "print(f'Average Validation Accuracy: {np.mean(val_accuracies):.4f}')\n",
    "print(f'Average Precision: {np.mean(val_precisions):.4f}')\n",
    "print(f'Average Recall: {np.mean(val_recalls):.4f}')\n",
    "print(f'Average F1 Score: {np.mean(val_f1s):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22b3bef-3fe0-415f-9906-b3f7020d1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot response function\n",
    "def get_response(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    sequence = vectorizer.transform([user_input])\n",
    "    prediction = model.predict(sequence)\n",
    "    tag = label_encoder.inverse_transform(prediction)[0]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a5cc9-6fdc-4599-956d-aebf93b2a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im disable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi there! What can I help you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im suffering from mental health\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: If your studies are affecting your mental health and wellbeing then pleasecontact our Student Wellbeing team [https://ask.herts.ac.uk/student-wellbeing]for support. You can alsocall our free 24/7 wellbeing helpline [https://ask.herts.ac.uk/student-wellbeing-24-hour-helpline]ran by Health Assured whenever you need to. You can also talk to staff in your School if you’re struggling.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im struggling in assignments \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: If you’re struggling with assignment deadlines and need more time, you could apply for an extension. If you think you need an additional seven days to hand in your assessment, you couldapply for a coursework extension [https://ask.herts.ac.uk/coursework-extensions]. You must apply for an extension before you submit your work. If you think you can’t submit your work by the deadline due to unexpected circumstances outside of your control, you couldsubmit an exceptional circumstances request. [https://ask.herts.ac.uk/exceptional-circumstances]In the first instance, please talk to your personal tutor, programme leader or cohort leader as they will be able to help and advise you. You must submit your exceptional circumstances request before you submit your work. If you are unsure or need more information, please talk to your personal tutor, programme leader or cohort leader.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im need support from herts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Herts SU’s Advice and Support team [https://hertssu.com/your-support/]provides free, confidential, and impartial advice and support on a range of student issues, including those of an academic nature, such as information on academic appeals and academic misconduct through to study skills support. If you want to get in touch with the team for advice regarding your academic experience, you canbook an appointment. [https://hertssu.com/your-support/] Herts SU also runsStudy Smart [https://hertssu.com/your-support/academic-advice/study-smart/], a scheme which is designed to accommodate your unique learning preferences to make you feel more confident with your assignments, revision techniques and exams. Sessions are one-to-one tutorials where you'll be exploring new study strategies that are designed to lead to efficient and interesting ways that you can use to approach your assignments and deadlines.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are the places to study in uni\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: At Herts, we have a variety of places that you can study from. We haveLearning Resources Centres (LRCs) [https://ask.herts.ac.uk/learning-resources-centres]on both campuses which are open 24/7, 365 days a year and have silent study areas, breakout rooms, group areas, computers and much more for you to use. If you’d like to study in one of our food outlets, visit the Art and Design Gallery Café and Café Rore on College Lane campus, and Café Ambition and Café Sport on de Havilland campus so you can work and get your caffeine fix. There are also other places across the University such as the Chapman Lounge and Hutton Hub on College Lane campus and the mezzanine and Grace Ononiwu Law Court building on de Havilland campus which have plenty of seating for you to use. View our TikTok of study spaces around campus. [https://www.tiktok.com/@uniofherts/video/7171372715234823430?_r=1&_t=8XlCqlMWi3R&dm_i=3CZ%2C84G9B%2C7FAFLN%2CX9JEK%2C1&is_from_webapp=v1&item_id=7171372715234823430]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is lrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The LRCs offer both online and offline support to help you with your studies at Herts. Their services include: Library SkillUP [https://ask.herts.ac.uk/library-skillup]– available on Canvas, Library SkillUP [https://ask.herts.ac.uk/library-skillup] consists of online modules to help guide you through your time at Herts. You can learn more about referencing, academic reading techniques, how to think and write critically and much more. Study Success Hubs [https://ask.herts.ac.uk/study-success-hub]– located on the ground floor of each LRC, the Study Success Hubs [https://ask.herts.ac.uk/study-success-hub] are here to help you succeed by helping you find the best resources for your assignments, tips on how to manage your workload and more! Information Managers [https://ask.herts.ac.uk/your-information-manager]– each subject area has a dedicated Information Manager who can help you find and use the most appropriate resources for your subject.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193d087-1bb4-4177-83aa-852ddfa96038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60809c52-45fd-4eac-8151-77bce71c8076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
