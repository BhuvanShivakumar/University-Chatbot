{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c097a08-4210-4cc1-aebf-0fb93b66c17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cb82cb9-b1f8-4dff-aa3e-3b3823b27d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, hinge_loss\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Convert tags to numerical labels\n",
    "unique_tags = list(set(tags))\n",
    "tag_to_num = {tag: num for num, tag in enumerate(unique_tags)}\n",
    "num_to_tag = {num: tag for tag, num in tag_to_num.items()}\n",
    "y = np.array([tag_to_num[tag] for tag in tags])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3eadc59-18b8-43a6-8aaa-3f73a65e4b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Model Metrics:\n",
      "Training Time: 0.01 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Train Hinge Loss: 0.0000\n",
      "Validation Hinge Loss: 0.0000\n",
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean Cross-Validation Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Vectorize patterns using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), stop_words='english')\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(patterns)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train_tfidf, X_val_tfidf, y_train_tfidf, y_val_tfidf = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the training set and measure training time\n",
    "start_time = time.time()\n",
    "svm_model_tfidf = make_pipeline(StandardScaler(with_mean=False), SVC(kernel='linear', probability=True))\n",
    "svm_model_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "training_time_tfidf = time.time() - start_time\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_tfidf = svm_model_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy_tfidf = accuracy_score(y_val_tfidf, y_val_pred_tfidf)\n",
    "\n",
    "# Calculate hinge loss on training and validation sets\n",
    "y_train_decision_tfidf = svm_model_tfidf.decision_function(X_train_tfidf)\n",
    "y_val_decision_tfidf = svm_model_tfidf.decision_function(X_val_tfidf)\n",
    "train_hinge_loss_tfidf = hinge_loss(y_train_tfidf, y_train_decision_tfidf, labels=list(tag_to_num.values()))\n",
    "val_hinge_loss_tfidf = hinge_loss(y_val_tfidf, y_val_decision_tfidf, labels=list(tag_to_num.values()))\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores_tfidf = cross_val_score(svm_model_tfidf, X_tfidf, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print TF-IDF model metrics\n",
    "print(\"\\nTF-IDF Model Metrics:\")\n",
    "print(f'Training Time: {training_time_tfidf:.2f} seconds')\n",
    "print(f'Validation Accuracy: {val_accuracy_tfidf:.4f}')\n",
    "print(f'Train Hinge Loss: {train_hinge_loss_tfidf:.4f}')\n",
    "print(f'Validation Hinge Loss: {val_hinge_loss_tfidf:.4f}')\n",
    "print(f'Cross-Validation Scores: {cross_val_scores_tfidf}')\n",
    "print(f'Mean Cross-Validation Score: {np.mean(cross_val_scores_tfidf):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "075b9366-62d6-4d81-b0f0-afdd37d13aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot using TF-IDF is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Good day! What do you need help with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi there! What can I help you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is stance on ai tools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The University's academic integrity policy (UPR AS14 Appendix III) [https://www.herts.ac.uk/__data/assets/pdf_file/0007/237625/AS14-Apx3-Academic-Misconduct-v17.0.pdf]sets out our stance on plagiarism including fake referencing which can often be the case with AI tools. Therefore, it is crucial thatyou do not use AI toolsto generate an assessment and submit it as your own work; to do so will constitute academic misconduct.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is external examiners\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The role of the External Examiner In the UK Higher Education system, Universities are responsible for the academic standards of the awards that they offer, and for the quality of the education they provide to enable students to meet those standards. The role of the external examiner is an essential part of the University’s quality assurance processes. They essentially externally ‘audit’ the programmes that they are appointed to, in terms of the attainment of academic standards and the quality of the education. The University of Hertfordshire appoints external examiners mainly from other Universities, but also from industry and/or the professions. They are qualified and experienced in the subject, have an understanding of the academic standards required for the award and are also independent of the University of Hertfordshire. As such, they are able to provide carefully considered advice on the academic standards of the programmes and/or modules to which they have been appointed, and can offer advice on good practice and how to enhance the quality of those programmes/modules. They are also able to offer an informed view of how standards compare with the same or similar awards at other UK Universities of which they have experience. It is important to note that whilst external examiners are full members of the Boards of Examiners to which they are appointed, the decisions of the Board are the collective, consensus views of all members of the Board. Another important feature of external examining in the UK is the provision of annual written reports to the University, based on what they have observed of the institution's assessment processes and the sample of student work that they have seen.  These reports provide invaluable independent feedback to the University at module and/or programme level. The University of Hertfordshire recognises the importance of the role of students in the management of academic standards and quality. External examiners' reports are therefore made available to student representatives, as part of the programme monitoring process. If you are not a student representative and would like to request a copy of the External Examiners’ reports relating to your programme, then please emailaqo@herts.ac.uk [mailto:aqo@herts.ac.uk], stating your ID number, the full title of your programme and your current year/level. A list of external examiners, by subject area, is also available viaaqo@herts.ac.uk [mailto:aqo@herts.ac.uk]. Please note that contacting external examiners regarding any aspect of your programme of study is prohibited. The University has appropriate internal mechanisms in place if you wish to raise a concern using the complaints or appeals procedures, as appropriate (links below): Student complaints procedure [https://ask.herts.ac.uk/making-a-complaint] Student appeals procedure [https://ask.herts.ac.uk/academic-appeals-requests-for-the-review-of-assessment-decisions]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def get_response_tfidf(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    X_user = tfidf_vectorizer.transform([user_input])\n",
    "    tag_prob = svm_model_tfidf.predict_proba(X_user)[0]\n",
    "    tag_index = np.argmax(tag_prob)\n",
    "    tag = num_to_tag[tag_index]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot using TF-IDF is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response_tfidf(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb078f-9e0a-4e81-8056-01bc9abd1267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9fbcf-b83f-4e80-a6c8-5563b4d6eef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3dc1ad1-b956-4e9b-ad9b-d60088f7e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import hinge_loss, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Convert tags to numerical labels\n",
    "unique_tags = list(set(tags))\n",
    "tag_to_num = {tag: num for num, tag in enumerate(unique_tags)}\n",
    "num_to_tag = {num: tag for tag, num in tag_to_num.items()}\n",
    "y = np.array([tag_to_num[tag] for tag in tags])\n",
    "\n",
    "# Vectorize patterns\n",
    "vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(patterns)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d89976-e7f8-4e09-8d5f-65016c580778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Grid Search): {'svc__C': 0.01, 'svc__degree': 2, 'svc__gamma': 1, 'svc__kernel': 'poly'}\n",
      "Validation Accuracy (Grid Search): 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the SVM model\n",
    "svm_model = make_pipeline(StandardScaler(with_mean=False), SVC(probability=True))\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svc__degree': [2, 3, 4, 5],\n",
    "    'svc__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params_grid = grid_search.best_params_\n",
    "print(f\"Best parameters (Grid Search): {best_params_grid}\")\n",
    "\n",
    "# Train and evaluate the Grid Search best model\n",
    "svm_model_grid = make_pipeline(\n",
    "    StandardScaler(with_mean=False), \n",
    "    SVC(C=best_params_grid['svc__C'], degree=best_params_grid['svc__degree'], gamma=best_params_grid['svc__gamma'], kernel=best_params_grid['svc__kernel'], probability=True)\n",
    ")\n",
    "svm_model_grid.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_grid = svm_model_grid.predict(X_val)\n",
    "val_accuracy_grid = accuracy_score(y_val, y_val_pred_grid)\n",
    "\n",
    "print(f\"Validation Accuracy (Grid Search): {val_accuracy_grid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03bcd87-8057-45a6-9b5c-a77771d1a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Random Search): {'svc__kernel': 'linear', 'svc__gamma': 10, 'svc__degree': 4, 'svc__C': 35.93813663804626}\n",
      "Validation Accuracy (Random Search): 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'svc__C': np.logspace(-2, 2, 10),  # 10 values between 0.01 and 100\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svc__degree': [2, 3, 4, 5],  # Degrees for polynomial kernel\n",
    "    'svc__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10]  # Various gamma values\n",
    "}\n",
    "\n",
    "# Perform Random Search with Cross-Validation\n",
    "random_search = RandomizedSearchCV(svm_model, param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Random Search\n",
    "best_params_random = random_search.best_params_\n",
    "print(f\"Best parameters (Random Search): {best_params_random}\")\n",
    "\n",
    "# Train and evaluate the Random Search best model\n",
    "svm_model_random = make_pipeline(\n",
    "    StandardScaler(with_mean=False), \n",
    "    SVC(C=best_params_random['svc__C'], degree=best_params_random['svc__degree'], gamma=best_params_random['svc__gamma'], kernel=best_params_random['svc__kernel'], probability=True)\n",
    ")\n",
    "svm_model_random.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_random = svm_model_random.predict(X_val)\n",
    "val_accuracy_random = accuracy_score(y_val, y_val_pred_random)\n",
    "\n",
    "print(f\"Validation Accuracy (Random Search): {val_accuracy_random:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a42fd8-d457-4df7-9804-e1544c3a046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model selected from Random Search.\n",
      "\n",
      "Average Metrics:\n",
      "Validation Accuracy: 1.0000\n",
      "Train Hinge Loss: 0.0000\n",
      "Validation Hinge Loss: 0.0000\n",
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean Cross-Validation Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the best model\n",
    "if val_accuracy_grid > val_accuracy_random:\n",
    "    best_model = svm_model_grid\n",
    "    best_params = best_params_grid\n",
    "    print(\"Best model selected from Grid Search.\")\n",
    "else:\n",
    "    best_model = svm_model_random\n",
    "    best_params = best_params_random\n",
    "    print(\"Best model selected from Random Search.\")\n",
    "\n",
    "# Calculate hinge loss on training and validation sets\n",
    "y_train_decision = best_model.decision_function(X_train)\n",
    "y_val_decision = best_model.decision_function(X_val)\n",
    "train_hinge_loss = hinge_loss(y_train, y_train_decision, labels=list(tag_to_num.values()))\n",
    "val_hinge_loss = hinge_loss(y_val, y_val_decision, labels=list(tag_to_num.values()))\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(best_model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_val_pred_grid if best_model == svm_model_grid else y_val_pred_random):.4f}')\n",
    "print(f'Train Hinge Loss: {train_hinge_loss:.4f}')\n",
    "print(f'Validation Hinge Loss: {val_hinge_loss:.4f}')\n",
    "print(f'Cross-Validation Scores: {cross_val_scores}')\n",
    "print(f'Mean Cross-Validation Score: {np.mean(cross_val_scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3e1c1-5dbd-4b6f-b8c2-207f1d8865ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  may i know more about appeal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: An academic appeal is a request from a student to the Dean of their School to review a decision made by the Board of Examiners about an assessment decision. If you want tomake an appeal [https://ask.herts.ac.uk/academic-appeals-requests-for-the-review-of-assessment-decisions], you must request a review of your results within 10 working days of their publication. You can also contact your programme leader or cohort leader, or Herts SU’s Advice and Support centre for guidance.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is mental health\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: If your studies are affecting your mental health and wellbeing then pleasecontact our Student Wellbeing team [https://ask.herts.ac.uk/student-wellbeing]for support. You can alsocall our free 24/7 wellbeing helpline [https://ask.herts.ac.uk/student-wellbeing-24-hour-helpline]ran by Health Assured whenever you need to. You can also talk to staff in your School if you’re struggling.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is lrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  explain university external examiners\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The role of the External Examiner In the UK Higher Education system, Universities are responsible for the academic standards of the awards that they offer, and for the quality of the education they provide to enable students to meet those standards. The role of the external examiner is an essential part of the University’s quality assurance processes. They essentially externally ‘audit’ the programmes that they are appointed to, in terms of the attainment of academic standards and the quality of the education. The University of Hertfordshire appoints external examiners mainly from other Universities, but also from industry and/or the professions. They are qualified and experienced in the subject, have an understanding of the academic standards required for the award and are also independent of the University of Hertfordshire. As such, they are able to provide carefully considered advice on the academic standards of the programmes and/or modules to which they have been appointed, and can offer advice on good practice and how to enhance the quality of those programmes/modules. They are also able to offer an informed view of how standards compare with the same or similar awards at other UK Universities of which they have experience. It is important to note that whilst external examiners are full members of the Boards of Examiners to which they are appointed, the decisions of the Board are the collective, consensus views of all members of the Board. Another important feature of external examining in the UK is the provision of annual written reports to the University, based on what they have observed of the institution's assessment processes and the sample of student work that they have seen.  These reports provide invaluable independent feedback to the University at module and/or programme level. The University of Hertfordshire recognises the importance of the role of students in the management of academic standards and quality. External examiners' reports are therefore made available to student representatives, as part of the programme monitoring process. If you are not a student representative and would like to request a copy of the External Examiners’ reports relating to your programme, then please emailaqo@herts.ac.uk [mailto:aqo@herts.ac.uk], stating your ID number, the full title of your programme and your current year/level. A list of external examiners, by subject area, is also available viaaqo@herts.ac.uk [mailto:aqo@herts.ac.uk]. Please note that contacting external examiners regarding any aspect of your programme of study is prohibited. The University has appropriate internal mechanisms in place if you wish to raise a concern using the complaints or appeals procedures, as appropriate (links below): Student complaints procedure [https://ask.herts.ac.uk/making-a-complaint] Student appeals procedure [https://ask.herts.ac.uk/academic-appeals-requests-for-the-review-of-assessment-decisions]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is assignment extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: If you’re struggling with assignment deadlines and need more time, you could apply for an extension. If you think you need an additional seven days to hand in your assessment, you couldapply for a coursework extension [https://ask.herts.ac.uk/coursework-extensions]. You must apply for an extension before you submit your work. If you think you can’t submit your work by the deadline due to unexpected circumstances outside of your control, you couldsubmit an exceptional circumstances request. [https://ask.herts.ac.uk/exceptional-circumstances]In the first instance, please talk to your personal tutor, programme leader or cohort leader as they will be able to help and advise you. You must submit your exceptional circumstances request before you submit your work. If you are unsure or need more information, please talk to your personal tutor, programme leader or cohort leader.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im struggling with assignments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hey! How can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  im disable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "def get_response(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    X_user = vectorizer.transform([user_input])\n",
    "    tag_prob = best_model.predict_proba(X_user)[0]\n",
    "    tag_index = np.argmax(tag_prob)\n",
    "    tag = num_to_tag[tag_index]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506850c4-75f7-436d-b3b7-9bcad19888e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
