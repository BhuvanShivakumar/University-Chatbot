{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4add0d-f8c9-4fad-ab5d-e134f8e32d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83135b8-5361-4efd-9474-283b9c190b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, hinge_loss\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Convert tags to numerical labels\n",
    "unique_tags = list(set(tags))\n",
    "tag_to_num = {tag: num for num, tag in enumerate(unique_tags)}\n",
    "num_to_tag = {num: tag for tag, num in tag_to_num.items()}\n",
    "y = np.array([tag_to_num[tag] for tag in tags])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adeaac75-23bb-429a-994c-c987f16b7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CountVectorizer Model Metrics:\n",
      "Training Time: 0.01 seconds\n",
      "Validation Accuracy: 1.0000\n",
      "Train Hinge Loss: 0.0000\n",
      "Validation Hinge Loss: 0.0000\n",
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean Cross-Validation Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Vectorize patterns using Bag-of-Words\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(patterns)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train_count, X_val_count, y_train_count, y_val_count = train_test_split(X_count, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the training set and measure training time\n",
    "start_time = time.time()\n",
    "svm_model_count = make_pipeline(StandardScaler(with_mean=False), SVC(kernel='linear', probability=True))\n",
    "svm_model_count.fit(X_train_count, y_train_count)\n",
    "training_time_count = time.time() - start_time\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_count = svm_model_count.predict(X_val_count)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy_count = accuracy_score(y_val_count, y_val_pred_count)\n",
    "\n",
    "# Calculate hinge loss on training and validation sets\n",
    "y_train_decision_count = svm_model_count.decision_function(X_train_count)\n",
    "y_val_decision_count = svm_model_count.decision_function(X_val_count)\n",
    "train_hinge_loss_count = hinge_loss(y_train_count, y_train_decision_count, labels=list(tag_to_num.values()))\n",
    "val_hinge_loss_count = hinge_loss(y_val_count, y_val_decision_count, labels=list(tag_to_num.values()))\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "cross_val_scores_count = cross_val_score(svm_model_count, X_count, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print CountVectorizer model metrics\n",
    "print(\"\\nCountVectorizer Model Metrics:\")\n",
    "print(f'Training Time: {training_time_count:.2f} seconds')\n",
    "print(f'Validation Accuracy: {val_accuracy_count:.4f}')\n",
    "print(f'Train Hinge Loss: {train_hinge_loss_count:.4f}')\n",
    "print(f'Validation Hinge Loss: {val_hinge_loss_count:.4f}')\n",
    "print(f'Cross-Validation Scores: {cross_val_scores_count}')\n",
    "print(f'Mean Cross-Validation Score: {np.mean(cross_val_scores_count):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c533b5bf-5c13-4bce-995a-183a1b4dd219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot using CountVectorizer is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi there! What can I help you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is external examiners\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def get_response_count(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    X_user = count_vectorizer.transform([user_input])\n",
    "    tag_prob = svm_model_count.predict_proba(X_user)[0]\n",
    "    tag_index = np.argmax(tag_prob)\n",
    "    tag = num_to_tag[tag_index]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot using CountVectorizer is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response_count(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70460453-900d-4483-bca7-497d325bd551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855084b-7f8d-4d71-b463-0b33f3912429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6436de61-f73c-4f3e-ae87-5c05652d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import hinge_loss, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "with open('Combined_training.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([char for char in sentence if char not in string.punctuation])\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(preprocess(pattern))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Convert tags to numerical labels\n",
    "unique_tags = list(set(tags))\n",
    "tag_to_num = {tag: num for num, tag in enumerate(unique_tags)}\n",
    "num_to_tag = {num: tag for tag, num in tag_to_num.items()}\n",
    "y = np.array([tag_to_num[tag] for tag in tags])\n",
    "\n",
    "# Vectorize patterns using Bag-of-Words\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(patterns)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8421f57-286f-4a06-b6a1-2960c63d2c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Grid Search): {'svc__C': 0.1, 'svc__degree': 2, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}\n",
      "Validation Accuracy (Grid Search): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = make_pipeline(StandardScaler(with_mean=False), SVC(probability=True))\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svc__degree': [2, 3, 4, 5],\n",
    "    'svc__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params_grid = grid_search.best_params_\n",
    "print(f\"Best parameters (Grid Search): {best_params_grid}\")\n",
    "\n",
    "# Train and evaluate the Grid Search best model\n",
    "svm_model_grid = make_pipeline(\n",
    "    StandardScaler(with_mean=False), \n",
    "    SVC(C=best_params_grid['svc__C'], degree=best_params_grid['svc__degree'], gamma=best_params_grid['svc__gamma'], kernel=best_params_grid['svc__kernel'], probability=True)\n",
    ")\n",
    "svm_model_grid.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_grid = svm_model_grid.predict(X_val)\n",
    "val_accuracy_grid = accuracy_score(y_val, y_val_pred_grid)\n",
    "\n",
    "print(f\"Validation Accuracy (Grid Search): {val_accuracy_grid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106f7e71-7b9f-462a-bfbe-84823a8cfc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Random Search): {'svc__kernel': 'linear', 'svc__gamma': 10, 'svc__degree': 4, 'svc__C': 35.93813663804626}\n",
      "Validation Accuracy (Random Search): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'svc__C': np.logspace(-2, 2, 10),  # 10 values between 0.01 and 100\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svc__degree': [2, 3, 4, 5],  # Degrees for polynomial kernel\n",
    "    'svc__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10]  # Various gamma values\n",
    "}\n",
    "\n",
    "# Perform Random Search with Cross-Validation\n",
    "random_search = RandomizedSearchCV(svm_model, param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Random Search\n",
    "best_params_random = random_search.best_params_\n",
    "print(f\"Best parameters (Random Search): {best_params_random}\")\n",
    "\n",
    "# Train and evaluate the Random Search best model\n",
    "svm_model_random = make_pipeline(\n",
    "    StandardScaler(with_mean=False), \n",
    "    SVC(C=best_params_random['svc__C'], degree=best_params_random['svc__degree'], gamma=best_params_random['svc__gamma'], kernel=best_params_random['svc__kernel'], probability=True)\n",
    ")\n",
    "svm_model_random.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_random = svm_model_random.predict(X_val)\n",
    "val_accuracy_random = accuracy_score(y_val, y_val_pred_random)\n",
    "\n",
    "print(f\"Validation Accuracy (Random Search): {val_accuracy_random:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b980d0-ccd3-44d9-8c16-5b15927e0255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model selected from Random Search.\n",
      "\n",
      "Average Metrics:\n",
      "Validation Accuracy: 1.0000\n",
      "Train Hinge Loss: 0.0000\n",
      "Validation Hinge Loss: 0.0000\n",
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean Cross-Validation Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select the best model\n",
    "if val_accuracy_grid > val_accuracy_random:\n",
    "    best_model = svm_model_grid\n",
    "    best_params = best_params_grid\n",
    "    print(\"Best model selected from Grid Search.\")\n",
    "else:\n",
    "    best_model = svm_model_random\n",
    "    best_params = best_params_random\n",
    "    print(\"Best model selected from Random Search.\")\n",
    "\n",
    "# Calculate hinge loss on training and validation sets\n",
    "y_train_decision = best_model.decision_function(X_train)\n",
    "y_val_decision = best_model.decision_function(X_val)\n",
    "train_hinge_loss = hinge_loss(y_train, y_train_decision, labels=list(tag_to_num.values()))\n",
    "val_hinge_loss = hinge_loss(y_val, y_val_decision, labels=list(tag_to_num.values()))\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(best_model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, y_val_pred_grid if best_model == svm_model_grid else y_val_pred_random):.4f}')\n",
    "print(f'Train Hinge Loss: {train_hinge_loss:.4f}')\n",
    "print(f'Validation Hinge Loss: {val_hinge_loss:.4f}')\n",
    "print(f'Cross-Validation Scores: {cross_val_scores}')\n",
    "print(f'Mean Cross-Validation Score: {np.mean(cross_val_scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190e222c-80e7-405e-bcad-e4e3a39166c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hey! How can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how are you \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me about places to study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: At Herts, we have a variety of places that you can study from. We haveLearning Resources Centres (LRCs) [https://ask.herts.ac.uk/learning-resources-centres]on both campuses which are open 24/7, 365 days a year and have silent study areas, breakout rooms, group areas, computers and much more for you to use. If you’d like to study in one of our food outlets, visit the Art and Design Gallery Café and Café Rore on College Lane campus, and Café Ambition and Café Sport on de Havilland campus so you can work and get your caffeine fix. There are also other places across the University such as the Chapman Lounge and Hutton Hub on College Lane campus and the mezzanine and Grace Ononiwu Law Court building on de Havilland campus which have plenty of seating for you to use. View our TikTok of study spaces around campus. [https://www.tiktok.com/@uniofherts/video/7171372715234823430?_r=1&_t=8XlCqlMWi3R&dm_i=3CZ%2C84G9B%2C7FAFLN%2CX9JEK%2C1&is_from_webapp=v1&item_id=7171372715234823430]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is teh best place sto study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi there! What can I help you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is best places to study \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: At Herts, we have a variety of places that you can study from. We haveLearning Resources Centres (LRCs) [https://ask.herts.ac.uk/learning-resources-centres]on both campuses which are open 24/7, 365 days a year and have silent study areas, breakout rooms, group areas, computers and much more for you to use. If you’d like to study in one of our food outlets, visit the Art and Design Gallery Café and Café Rore on College Lane campus, and Café Ambition and Café Sport on de Havilland campus so you can work and get your caffeine fix. There are also other places across the University such as the Chapman Lounge and Hutton Hub on College Lane campus and the mezzanine and Grace Ononiwu Law Court building on de Havilland campus which have plenty of seating for you to use. View our TikTok of study spaces around campus. [https://www.tiktok.com/@uniofherts/video/7171372715234823430?_r=1&_t=8XlCqlMWi3R&dm_i=3CZ%2C84G9B%2C7FAFLN%2CX9JEK%2C1&is_from_webapp=v1&item_id=7171372715234823430]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is ai tools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Good day! What do you need help with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is the use of ai tools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Good day! What do you need help with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def get_response(user_input):\n",
    "    user_input = preprocess(user_input)\n",
    "    X_user = vectorizer.transform([user_input])\n",
    "    tag_prob = best_model.predict_proba(X_user)[0]\n",
    "    tag_index = np.argmax(tag_prob)\n",
    "    tag = num_to_tag[tag_index]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5deb41f-36dc-441b-a7ff-8930c2b794e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
